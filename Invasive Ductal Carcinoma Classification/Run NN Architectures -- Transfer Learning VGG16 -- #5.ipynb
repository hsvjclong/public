{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Run NN Architectures -- Transfer Learning VGG16 -- #5.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNFy9gzHpkOdRuGr0v3Vui1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"XmCWQ3B6Vinu","colab_type":"text"},"source":["## Mount Google Drive in Colab"]},{"cell_type":"code","metadata":{"id":"AscU9XBSigLE","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sH33QHemVn4b","colab_type":"text"},"source":["## Perform imports"]},{"cell_type":"code","metadata":{"id":"Uy3USZXrjKOR","colab_type":"code","outputId":"209ab5ec-68e1-4448-a2fc-11aec893f9f2","executionInfo":{"status":"ok","timestamp":1585944417768,"user_tz":360,"elapsed":5817,"user":{"displayName":"James Long","photoUrl":"","userId":"09696276239741213637"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import numpy as np\n","%tensorflow_version 1.x\n","import keras\n","from keras.layers import Input, Dense\n","from keras.models import Model\n","from keras.optimizers import SGD\n","from keras.applications.vgg16 import VGG16, preprocess_input as ppi_vgg16\n","import json"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"aVe7TZGeVrTV","colab_type":"text"},"source":["## Load balanced dataset"]},{"cell_type":"code","metadata":{"id":"pufhu8eTGSk7","colab_type":"code","colab":{}},"source":["data = np.load('/content/drive/My Drive/Final Capstone/Balanced Data.npy')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hFRlvb94VtWm","colab_type":"text"},"source":["## Separate image data from label data"]},{"cell_type":"code","metadata":{"id":"e6aSgTJiGSie","colab_type":"code","colab":{}},"source":["# image data\n","X = data[:, :-1]\n","# label data\n","Y = data[:, -1:]\n","del data"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9CTFA0kOV6kC","colab_type":"text"},"source":["## Reshape image and label data and create one-hot encoding for label data"]},{"cell_type":"code","metadata":{"id":"tA8-zAohGSgv","colab_type":"code","colab":{}},"source":["# reshape image data to 50 x 50 x 3 format\n","X = np.reshape(X, (X.shape[0], 50, 50, 3), order='C')\n","# reshape label data to 1-D array\n","Y = np.reshape(Y, (Y.shape[0]))\n","# create one-hot encoding for label data\n","Y = keras.utils.to_categorical(Y, 2, 'float32')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UkUIeUXvWPVk","colab_type":"text"},"source":["## VGG16 Models\n","\n","Four models are created using using the VGG16 model as a basis and fit to the training set.  Two models are transfer learning models based on freezing the weights from the 'imagenet' training.  In one of these models, only a dense prediction layer is added.  In the other, a hidden dense layer and a dense prediction layer are added.  Two other models are created that simply make use of the architecture of the VGG16 model.  These models do not use the weights from 'imagenet' training.  Similarly to the models that use the pretrained weights, one of these models only has a dense prediction layer while the other has a hidden dense layer and a dense prediction layer.  The same method that was used to train the other 2-D Convolutional Neural Networks is used to train these models."]},{"cell_type":"code","metadata":{"id":"N5sM_Mw8ZOvg","colab_type":"code","colab":{}},"source":["# fraction of data to use for validation--taken from the bottom of the dataset by default in Keras\n","val_split = 0.2\n","# initial learning rate used in optimizer\n","initial_lr = 0.01\n","# width of hidden layer used prior to prediction dense layer\n","hidden_dense_size = 64"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"84rYev86WWAt","colab_type":"code","colab":{}},"source":["# see 'Run NN Architectures -- #4.ipynb' for commented version of this function\n","def optimize_model(model, X, Y, val_split, initial_lr):\n","  epoch_count = 0\n","  min_epochs = 5\n","  max_epochs = 20\n","  history_dict = None\n","  sgd = SGD(lr=initial_lr)\n","  sgd_lr = sgd.get_config()['lr']\n","  # while loop based on model train accuracy convergence\n","  while (True):\n","    # while loop based on learning rate reduction\n","    while (True):\n","      model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n","      old_weights = model.get_weights()\n","      history = model.fit(X, Y, epochs=1, validation_split=val_split, verbose=1)\n","\n","      if (history_dict == None):\n","        history_dict = history.history\n","        break\n","      else:\n","        last_loss = history_dict['loss'][len(history_dict['loss']) - 1]\n","        curr_loss = history.history['loss'][0]\n","        if (curr_loss <= last_loss):\n","          for key in history_dict.keys():\n","            history_dict[key].append(history.history[key][0])\n","          break\n","        else:\n","          sgd = SGD(lr=sgd_lr/2)\n","          sgd_lr = sgd.get_config()['lr']\n","          model.set_weights(old_weights)\n","\n","    epoch_count += 1\n","\n","    if (epoch_count >= min_epochs):\n","      if (epoch_count == max_epochs):\n","        break\n","      else:\n","        if (history_dict['val_acc'][epoch_count - 1] < history_dict['val_acc'][epoch_count - 2]):\n","          break\n","  return history_dict"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DmF6tTElqZxO","colab_type":"code","colab":{}},"source":["# preprocess input so that it is compatible with how input was preprocessed for training of VGG16 model\n","X_vgg16 = ppi_vgg16(X * 255)\n","del X"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gaOv93VVqZr3","colab_type":"code","colab":{}},"source":["# VGG16 model with frozen pretrained weights and prediction dense layer\n","\n","model_vgg16 = VGG16(include_top=False, weights='imagenet', input_shape=X_vgg16.shape[1:4], pooling='max')\n","\n","# freeze pretrained weights\n","for layer in model_vgg16.layers:\n","  layer.trainable = False\n","\n","input_layer = Input(shape=X_vgg16.shape[1:4])\n","model_vgg16_layer = model_vgg16(input_layer)\n","output_layer = Dense(units=2, activation='softmax')(model_vgg16_layer)\n","model = Model(input_layer, output_layer)\n","\n","output_dict = optimize_model(model, X_vgg16, Y, val_split, initial_lr)\n","\n","with open('/content/drive/My Drive/Final Capstone/Model Logs/vgg16_d.json', 'w') as f:\n","  json.dump(output_dict, f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uACY0lbwwDTS","colab_type":"code","colab":{}},"source":["# VGG16 model with frozen pretrained weights, hidden dense layer, and dense prediction layer\n","\n","model_vgg16 = VGG16(include_top=False, weights='imagenet', input_shape=X_vgg16.shape[1:4], pooling='max')\n","\n","# freeze pretrained weights\n","for layer in model_vgg16.layers:\n","  layer.trainable = False\n","\n","input_layer = Input(shape=X_vgg16.shape[1:4])\n","model_vgg16_layer = model_vgg16(input_layer)\n","output_layer = Dense(units=hidden_dense_size, activation='relu')(model_vgg16_layer)\n","output_layer1 = Dense(units=2, activation='softmax')(output_layer)\n","model = Model(input_layer, output_layer1)\n","\n","output_dict = optimize_model(model, X_vgg16, Y, val_split, initial_lr)\n","\n","with open('/content/drive/My Drive/Final Capstone/Model Logs/vgg16_d_d.json', 'w') as f:\n","  json.dump(output_dict, f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vVxcRXtWcrW5","colab_type":"code","colab":{}},"source":["# restore data to form from before preprocessing for VGG16\n","del X_vgg16\n","data = np.load('/content/drive/My Drive/Final Capstone/Balanced Data.npy')\n","X = data[:, :-1]\n","Y = data[:, -1:]\n","del data\n","X = np.reshape(X, (X.shape[0], 50, 50, 3), order='C')\n","Y = np.reshape(Y, (Y.shape[0]))\n","Y = keras.utils.to_categorical(Y, 2, 'float32')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nIe-97dHtzWw","colab_type":"code","colab":{}},"source":["# VGG16 model without pretrained weights and with dense prediction layer\n","\n","model_vgg16 = VGG16(include_top=False, weights=None, input_shape=X.shape[1:4], pooling='max')\n","input_layer = Input(shape=X.shape[1:4])\n","model_vgg16_layer = model_vgg16(input_layer)\n","output_layer = Dense(units=2, activation='softmax')(model_vgg16_layer)\n","model = Model(input_layer, output_layer)\n","\n","output_dict = optimize_model(model, X, Y, val_split, initial_lr)\n","\n","with open('/content/drive/My Drive/Final Capstone/Model Logs/vgg16_d_np.json', 'w') as f:\n","  json.dump(output_dict, f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mKPDtwDHu-Ky","colab_type":"code","colab":{}},"source":["# VGG16 model without pretrained weights and with hidden dense layer and dense prediction layer\n","\n","model_vgg16 = VGG16(include_top=False, weights=None, input_shape=X.shape[1:4], pooling='max')\n","input_layer = Input(shape=X.shape[1:4])\n","model_vgg16_layer = model_vgg16(input_layer)\n","output_layer = Dense(units=hidden_dense_size, activation='relu')(model_vgg16_layer)\n","output_layer1 = Dense(units=2, activation='softmax')(output_layer)\n","model = Model(input_layer, output_layer1)\n","\n","output_dict = optimize_model(model, X, Y, val_split, initial_lr)\n","\n","with open('/content/drive/My Drive/Final Capstone/Model Logs/vgg16_d_d_np.json', 'w') as f:\n","  json.dump(output_dict, f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gzygTS4iS2K6","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}