{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Autoencoder -- #8.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPRtQrg7Rigxrvc4Y/BLX0O"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"FbCFYCOB_qlj","colab_type":"text"},"source":["## Mount Google Drive in Colab"]},{"cell_type":"code","metadata":{"id":"AscU9XBSigLE","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9tFpyvup_t9k","colab_type":"text"},"source":["## Perform imports"]},{"cell_type":"code","metadata":{"id":"Uy3USZXrjKOR","colab_type":"code","outputId":"59e230a7-ba30-4b2d-92f4-f4f7cd5e6d37","executionInfo":{"status":"ok","timestamp":1586056807229,"user_tz":360,"elapsed":4041,"user":{"displayName":"James Long","photoUrl":"","userId":"09696276239741213637"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import numpy as np\n","%tensorflow_version 1.x\n","import keras\n","from keras.layers import Input, Dense, Conv2D, Flatten, Conv2DTranspose\n","from keras.models import Model\n","from keras.optimizers import SGD"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"vMshGwhX_7JQ","colab_type":"text"},"source":["## Load balanced dataset"]},{"cell_type":"code","metadata":{"id":"pufhu8eTGSk7","colab_type":"code","colab":{}},"source":["data = np.load('/content/drive/My Drive/Final Capstone/Balanced Data.npy')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FssAac9XAADC","colab_type":"text"},"source":["## Separate image data from label data"]},{"cell_type":"code","metadata":{"id":"e6aSgTJiGSie","colab_type":"code","colab":{}},"source":["# image data\n","X = data[:, :-1]\n","# label data\n","Y = data[:, -1:]\n","del data"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DV6rznjnAGCY","colab_type":"text"},"source":["## Reshape image and label data and create one-hot encoding for label data"]},{"cell_type":"code","metadata":{"id":"tA8-zAohGSgv","colab_type":"code","colab":{}},"source":["# reshape image data to 50 x 50 x 3 format\n","X = np.reshape(X, (X.shape[0], 50, 50, 3), order='C')\n","# reshape label data to 1-D array\n","Y = np.reshape(Y, (Y.shape[0]))\n","# create one-hot encoding for label data\n","Y = keras.utils.to_categorical(Y, 2, 'float32')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9pGSlfmTAMw5","colab_type":"text"},"source":["## Create, compile, and fit autoencoder"]},{"cell_type":"code","metadata":{"id":"KfQVZdWcv2V4","colab_type":"code","colab":{}},"source":["input_layer = Input(shape=X.shape[1:4])\n","encode_layer1 = Conv2D(filters=32, kernel_size=(3, 3), data_format='channels_last', activation='relu')(input_layer)\n","encode_layer2 = Conv2D(filters=32, kernel_size=(3, 3), data_format='channels_last', activation='relu')(encode_layer1)\n","decode_layer1 = Conv2DTranspose(filters=32, kernel_size=(3, 3), data_format='channels_last', activation='relu')(encode_layer2)\n","decode_layer2 = Conv2DTranspose(filters=3, kernel_size=(3, 3), data_format='channels_last', activation='sigmoid')(decode_layer1)\n","model = Model(input_layer, decode_layer2)\n","\n","model.compile(optimizer='sgd', loss='mse')\n","model.fit(X, X, epochs=30, verbose=1, validation_split=0.2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gKYiTbKeAS_E","colab_type":"text"},"source":["## Extract encoder from autoencoder"]},{"cell_type":"code","metadata":{"id":"fUo53BkQJ3vF","colab_type":"code","colab":{}},"source":["encoder = Model(model.input, model.layers[2].output)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ih_hdAwFAV-3","colab_type":"text"},"source":["## Create model that uses encoder output as input to dense layers"]},{"cell_type":"code","metadata":{"id":"0DANY-xhHSbn","colab_type":"code","colab":{}},"source":["flatten_layer = Flatten(data_format='channels_last')(encoder.output)\n","output_layer = Dense(units=64, activation='relu')(flatten_layer)\n","output_layer1 = Dense(units=2, activation='softmax')(output_layer)\n","\n","overall_model = Model(encoder.input, output_layer1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vASIhftkAe2L","colab_type":"text"},"source":["## Train and evaluate model\n","\n","The model is trained and evaluated similarly to the other architectures."]},{"cell_type":"code","metadata":{"id":"-lwLi9qMHag1","colab_type":"code","colab":{}},"source":["# function used to train models, same as function of same name in 'Run NN Architectures -- #4.ipynb'\n","def optimize_model(model, X, Y, val_split, initial_lr):\n","  epoch_count = 0\n","  min_epochs = 5\n","  max_epochs = 20\n","  history_dict = None\n","  sgd = SGD(lr=initial_lr)\n","  sgd_lr = sgd.get_config()['lr']\n","  # while loop based on model train accuracy convergence\n","  while (True):\n","    # while loop based on learning rate reduction\n","    while (True):\n","      model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n","      old_weights = model.get_weights()\n","      history = model.fit(X, Y, epochs=1, validation_split=val_split, verbose=1)\n","\n","      if (history_dict == None):\n","        history_dict = history.history\n","        break\n","      else:\n","        last_loss = history_dict['loss'][len(history_dict['loss']) - 1]\n","        curr_loss = history.history['loss'][0]\n","        if (curr_loss <= last_loss):\n","          for key in history_dict.keys():\n","            history_dict[key].append(history.history[key][0])\n","          break\n","        else:\n","          sgd = SGD(lr=sgd_lr/2)\n","          sgd_lr = sgd.get_config()['lr']\n","          model.set_weights(old_weights)\n","\n","    epoch_count += 1\n","\n","    if (epoch_count >= min_epochs):\n","      if (epoch_count == max_epochs):\n","        break\n","      else:\n","        if (history_dict['val_acc'][epoch_count - 1] < history_dict['val_acc'][epoch_count - 2]):\n","          break\n","  return history_dict"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KPr0bR-CHaZa","colab_type":"code","colab":{}},"source":["results_dict = optimize_model(overall_model, X, Y, val_split=0.2, initial_lr=0.01)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fOeWkYnPH329","colab_type":"code","colab":{}},"source":["val_acc_list = results_dict['val_acc']\n","\n","if (len(val_acc_list) > 5):\n","  max_epoch = len(val_acc_list) - 1\n","else:\n","  begin_index = len(val_acc_list) - 1\n","  while (True):\n","    if (val_acc_list[begin_index] >= val_acc_list[begin_index - 1]):\n","      max_epoch = begin_index + 1\n","      break\n","    else:\n","      begin_index -= 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QDZySLv5NTPj","colab_type":"code","colab":{}},"source":["def optimize_model(model, X, Y, val_split, initial_lr, epoch_to_stop):\n","  epoch_count = 0\n","  history_dict = None\n","  sgd = SGD(lr=initial_lr)\n","  sgd_lr = sgd.get_config()['lr']\n","  # while loop based on model train accuracy convergence\n","  while (True):\n","    # while loop based on learning rate reduction\n","    while (True):\n","      model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n","      old_weights = model.get_weights()\n","      history = model.fit(X, Y, epochs=1, validation_split=val_split, verbose=1)\n","\n","      if (history_dict == None):\n","        history_dict = history.history\n","        break\n","      else:\n","        last_loss = history_dict['loss'][len(history_dict['loss']) - 1]\n","        curr_loss = history.history['loss'][0]\n","        if (curr_loss <= last_loss):\n","          for key in history_dict.keys():\n","            history_dict[key].append(history.history[key][0])\n","          break\n","        else:\n","          sgd = SGD(lr=sgd_lr/2)\n","          sgd_lr = sgd.get_config()['lr']\n","          model.set_weights(old_weights)\n","\n","    epoch_count += 1\n","\n","    if (epoch_count >= epoch_to_stop):\n","      break\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5OwW94HfNbhU","colab_type":"code","colab":{}},"source":["def evaluate_model(X_val, Y_val, model):\n","  Y_pred = model.predict(X_val)\n","  pos_correct = 0\n","  neg_correct = 0\n","  pos = 0\n","  neg = 0\n","  for i in range(Y_pred.shape[0]):\n","    true = np.argmax(Y_val[i])\n","    pred = np.argmax(Y_pred[i])\n","    if (true == 1):\n","      pos += 1\n","      if (true == pred):\n","        pos_correct += 1\n","    elif (true == 0):\n","      neg += 1\n","      if (true == pred):\n","        neg_correct += 1\n","  \n","  sensitivity = (pos_correct/pos) * 100\n","  specificity = (neg_correct/neg) * 100\n","  accuracy = (pos_correct + neg_correct) / (pos + neg) * 100\n","  \n","  print('Sensitivity:  {}%\\nSpecificity:  {}%\\nAccuracy:  {}%'.format(sensitivity, specificity, accuracy))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mWYsWUPBOmLF","colab_type":"code","colab":{}},"source":["from math import ceil\n","X_val = X[ceil(X.shape[0] * (1 - 0.2)):]\n","Y_val = Y[ceil(X.shape[0] * (1 - 0.2)):]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qTV0_oGeNbYX","colab_type":"code","colab":{}},"source":["flatten_layer = Flatten(data_format='channels_last')(encoder.output)\n","output_layer = Dense(units=64, activation='relu')(flatten_layer)\n","output_layer1 = Dense(units=2, activation='softmax')(output_layer)\n","\n","overall_model = Model(encoder.input, output_layer1)\n","\n","trained_model = optimize_model(overall_model, X, Y, val_split=0.2, initial_lr=0.01, epoch_to_stop=max_epoch)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bk3XeMwsRWE0","colab_type":"code","outputId":"4c3ffeb6-fb84-4fbf-84aa-e1ab3c2aedb3","executionInfo":{"status":"ok","timestamp":1586058666910,"user_tz":360,"elapsed":4050,"user":{"displayName":"James Long","photoUrl":"","userId":"09696276239741213637"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["evaluate_model(X_val, Y_val, trained_model)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Sensitivity:  79.07081063761615%\n","Specificity:  89.02024902527984%\n","Accuracy:  84.09242390579871%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yurF-onnBNgf","colab_type":"text"},"source":["The model using an autoencoder to perform feature extraction results in roughly a similar accuracy than the one selected from the other models but has greater volatility between the sensitivity and specificity.  Therefore, the model chosen from the architecture not using an autoencoder is selected for grid searching of hyperparameters."]},{"cell_type":"code","metadata":{"id":"B17IC9cndpNj","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}